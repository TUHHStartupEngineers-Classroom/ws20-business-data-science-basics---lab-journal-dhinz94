---
title: "Journal (reproducible report)"
author: "Dominic Hinz"
date: "2020-12-06"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: true
    toc_depth: 3
    #code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```

<!-- **IMPORTANT:** You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing. -->

<!-- This is an `.Rmd` file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a \# in front of your text, it will create a top level-header. -->

<!-- # My first post -->

<!-- Last compiled: `r Sys.Date()` -->

<!-- Notice that whatever you define as a top level header, automatically gets put into the table of contents bar on the left.  -->

<!-- ## Second level header -->

<!-- You can add more headers by adding more hashtags. These won't be put into the table of contents -->

<!-- ### third level header -->

<!-- Here's an even lower level header -->

<!-- # My second post (note the order) -->

<!-- Last compiled: `r Sys.Date()` -->

<!-- I'm writing this tutorial going from the top down. And, this is how it will be printed. So, notice the second post is second in the list. If you want your most recent post to be at the top, then make a new post starting at the top. If you want the oldest first, do, then keep adding to the bottom -->

<!-- # Adding R stuff -->

<!-- So far this is just a blog where you can write in plain text and serve your writing to a webpage. One of the main purposes of this lab journal is to record your progress learning R. The reason I am asking you to use this process is because you can both make a website, and a lab journal, and learn R all in R-studio. This makes everything really convenient and in the same place.  -->

<!-- So, let's say you are learning how to make a histogram in R. For example, maybe you want to sample 100 numbers from a normal distribution with mean = 0, and standard deviation = 1, and then you want to plot a histogram. You can do this right here by using an r code block, like this: -->

<!-- ```{r} -->
<!-- samples <- rnorm(100, mean=0, sd=1) -->
<!-- hist(samples) -->
<!-- ``` -->

<!-- When you knit this R Markdown document, you will see that the histogram is printed to the page, along with the R code. This document can be set up to hide the R code in the webpage, just delete the comment (hashtag) from the cold folding option in the yaml header up top. For purposes of letting yourself see the code, and me see the code, best to keep it the way that it is. You'll learn that all of these things and more can be customized in each R code block. -->



# Introduction - Bike Stores

```{r}
library('tidyverse')
library('readxl')

#options(tibble.width = Inf) # displays all columns.
#options(tibble.print_max = 10) #show only specific row amount

data_path='/media/dominic/Windows/Users/Dominic/Documents/Studium/A-Master 5. Semester/Data Science/data/DS_101/00_data/01_bike_sales/01_raw_data/'

# read files
bikes=read_excel(paste(data_path,'bikes.xlsx',sep = ''))
shops=read_excel(paste(data_path,'bikeshops.xlsx',sep = ''))
orders=read_excel(paste(data_path,'orderlines.xlsx',sep = ''))

# join all tables into one dataframe 
joined=left_join(orders,shops,by=c('customer.id'='bikeshop.id'))
joined=left_join(joined,bikes,by=c('product.id'='bike.id'))

# split location column in city,state column
joined=separate(joined,location,into=c('city','state'),sep=', ')
# split order.date column in year,month,date column
joined=separate(joined,order.date,into=c('year','month','day'),sep='-')

#create column with total price per order
joined$total_price=joined$price* joined$quantity

# get list of unique states, cities, years
states = unique(joined$state)
cities = unique(joined$city)
years = unique(joined$year)

#empty list for revenues,years,states
revenues_vector=c()
years_vector=c()
states_vector=c()

#filter dataframe for all orders in a specific state and year and calculate the corresponding revenue
for (s in states){
  #all orders in one state
  orders_state=joined[joined$state==s,]
  for (y in years){
    
    #all orders in one year in current state
    order_year=orders_state[orders_state$year==y,]
    #calculate revenue
    revenue=sum(order_year$total_price)
    
    #append vectors
    revenues_vector=c(revenues_vector,revenue)
    years_vector=c(years_vector,y)
    states_vector=c(states_vector,s)
  }
}

#create dataframe from created vectors
year_state_revenues=tibble(state=states_vector,revenue=revenues_vector,year=years_vector)

# plot revenues over state
p=ggplot(data=year_state_revenues,aes(y=revenue,x=state)) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(
    title = "Revenue by state",
    x = "State", # Override defaults for x and y
    y = "Revenue [€]"
  )+
  scale_y_continuous(labels = scales::dollar_format(big.mark = ".",
                                                    decimal.mark = ",",
                                                    prefix = "",
                                                    suffix = " €"))

plot(p)

# group plot, revenue over year for every state in a separate barplot
p=ggplot(data=year_state_revenues,aes(y=revenue,x=year)) +
  geom_bar(stat = "identity") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(
    title    = "Revenue by state",
    x = "State", # Override defaults for x and y
    y = "Revenue [€]"
  )+
  scale_y_continuous(labels = scales::dollar_format(big.mark = ".", 
                                                    decimal.mark = ",", 
                                                    prefix = "", 
                                                    suffix = " €")) +
  facet_wrap(~state)

plot(p)





```

# Data Acquisition via API - Star Wars

```{r}

library(tidyverse)
library(httr)
library(jsonlite)

# function to provide clean object from url
path_to_object=function (path){
  result=GET(path)
  content=rawToChar(result$content)
  object=fromJSON(content,flatten = TRUE)
  return(object)
              
}

base_url="https://swapi.dev/api/"

base_content=path_to_object(base_url)

# get table names from base categories
tables=names(base_content)

table_list=list()

# loop through every table
for (i in 1:length(tables)){
  table_name=tables[[i]]
  table_url=base_content[table_name][[1]]
  
  # get content of table
  table_content=path_to_object(table_url)
  # get amount of instances in table
  instance_amount=table_content$count
  
  instances=list()
  #loop over every instance and create row for table
  for (j in 1:instance_amount){
    instance_url=paste(table_url,j,'/',sep='')
    instance_content=path_to_object(instance_url)
    row=enframe(instance_content)
    row=pivot_wider(row)
    #collect all rows in list
    instances[[j]]=row

  }
  
  # combine every row to a table dataframe
  table=bind_rows(instances)
  
  #collect all tables in list
  table_list[[i]]=table


}

print("print only person table as example (print as tibble was very ugly, I used glimpse() here)")
glimpse(table_list[[1]])


```

# Data Acquisition via Scraping - Bike website

```{r}
library(rvest)
library(tidyverse)

#get html for mountainbike category
base=read_html('https://www.rosebikes.de/fahrräder/mtb')

# get html nodes  for all bikes
bikes=html_nodes(base,css = 'li.catalog-category-bikes__list-item')

names=list()
euros=list()
cents=list()
i=1

#loop over all bike nodes
for (bike in bikes){
  #get text of object with bike name
  name=html_text(html_node(bike,css='span.catalog-category-bikes__title-text'))
  # remove unnecessary strings from name
  name=str_replace_all(name, '\n', '')
  
  # get text of object with bike price
  price=html_text(html_node(bike,css='div.catalog-category-bikes__price-title'))
  # remove unnecessary strings from price
  price=str_replace_all(price, '\n', '')
  price=str_replace_all(price, '€', '')
  price=str_replace_all(price, 'ab ', '')
  price=str_replace_all(price, " ", "")
  price=str_replace_all(price,'[.]','')

  #split into euro and cent
  price_splitted=str_split(price,',')[[1]]
  
  # check if  price is available and convert to integer
  if (length(price_splitted)==2){
    euro=strtoi(price_splitted[[1]])
    cent=strtoi(substring(price_splitted[[2]],1,2)) # get only 2 first characters from cent string becaus last whitespace cannot be removed (did not find out why)
  }else{
    next # skip bike if no price is available
  }
  
  #collect all model names and prices
  names[[i]]=name
  euros[[i]]=euro
  cents[[i]]=cent
  
  i=i+1

}

#create datafram from bike models and prices
df=tibble(name=names,euro=euros,cent=cents)
#unnest lists in column
df=unnest(df,cols=c(name,euro,cent))
print(df)

```

# Data Wrangling - Patent Analysis

```{r}

```



# Data Visualization - Covid-19

```{r}
library(tidyverse)
covid_data_tbl <- read_csv("https://opendata.ecdc.europa.eu/covid19/casedistribution/csv")

# sort for date
covid_data_tbl=arrange(covid_data_tbl,countriesAndTerritories,year,month,day)
# convert date as "Date" datatype
covid_data_tbl[,'dateRep']=as.Date(covid_data_tbl$dateRep, "%d/%m/%Y")

#calculate cumulated cases and deaths
covid_data_tbl=mutate(group_by(covid_data_tbl, countriesAndTerritories),cum_death=cumsum(deaths))
covid_data_tbl=mutate(group_by(covid_data_tbl, countriesAndTerritories),cum_cases=cumsum(cases))

#calculate death rate by cumulated deaths/population
covid_data_tbl=mutate(covid_data_tbl,mortality_rate=cum_death/(popData2019+1e-8))

# function that filters for data of only one state
get_cases_from_state=function(state){
  cases=covid_data_tbl[covid_data_tbl$countriesAndTerritories==state,]
  return(cases)
}
  
#get cases of different states
cases_germany=get_cases_from_state('Germany')
cases_usa=get_cases_from_state('United_States_of_America')
cases_uk=get_cases_from_state('United_Kingdom')
cases_spain=get_cases_from_state('Spain')
cases_france=get_cases_from_state('France')

# plot cumulative cases for some states
colors <- c("Germany" = "blue", "United_States_of_America" = "red", "United_Kingdom" = "orange",'Spain'='orange','France'='black')
p=ggplot()+ 
  geom_line(data=cases_germany,aes(y=cum_cases,x=dateRep,color='Germany')) +
  geom_line(data=cases_usa,aes(y=cum_cases,x=dateRep,color='United_States_of_America'))+
  geom_line(data=cases_uk,aes(y=cum_cases,x=dateRep,color='United_Kingdom'))+
  geom_line(data=cases_spain,aes(y=cum_cases,x=dateRep,color='Spain'))+
  geom_line(data=cases_france,aes(y=cum_cases,x=dateRep,color='France'))+
  labs(title = 'Cumulative Cases',x='date',y='cases',color='Legend')

plot(p)

# get most recent mortality rates
last_date=max(covid_data_tbl$dateRep)
covid_last=covid_data_tbl[covid_data_tbl$dateRep==last_date,]

# clean up dataframe
covid_last$countriesAndTerritories <- lapply(covid_last$countriesAndTerritories, gsub, pattern = "_", replacement = " ")
covid_last$countriesAndTerritories <- lapply(covid_last$countriesAndTerritories, gsub, pattern = "United Kingdom", replacement = "UK")
covid_last$countriesAndTerritories <- lapply(covid_last$countriesAndTerritories, gsub, pattern = "United States of America", replacement = "USA")
covid_last$countriesAndTerritories <- lapply(covid_last$countriesAndTerritories, gsub, pattern = "Czechia", replacement = "Czech Republic")
covid_last=unnest(covid_last,cols=c(countriesAndTerritories))

# load world map data
world <- map_data("world")

# join world map data and table with most recent covid data
joined=right_join(world,covid_last,by=c('region'='countriesAndTerritories'))
# drop states where no data is available (e.g vatican)
joined=joined[!is.na(joined$mortality_rate),]


# plot mortality rates on world map
p=ggplot() +
  geom_map(
    data = joined, map = world, aes(long, lat, map_id = region,fill = mortality_rate), color = "black", size = 0.1)+
    labs(title = 'Mortality Rate',color='Legend')+
    scale_fill_gradient(low = "red", high = "black",labels=scales::percent)
    
plot(p)

```